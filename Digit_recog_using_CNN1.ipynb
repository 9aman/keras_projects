{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we seed the random number initializer for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the Conv2D in keras takes input in the format [pixels][height][width] we need to reshape our input. If its RGB\n",
    "# then pixels value will be 3 but we have gray scale images so pixels value is 1\n",
    "# Final shape is [no_of_samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0],1,28,28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0],1,28,28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we will proceed by normalising the pixel values as we did before and one hot encode the classes\n",
    "\n",
    "# Normalise the pixel values\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# One hot encoding of the categories\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will store the number of classes \n",
    "num_classes  = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are first building a simple convolutional model to have the following specifications : \n",
    "# First layer comprises of a convolution layer consisting of 32 feauture maps(fliters) with size 5*5 and relu activation\n",
    "# Second layer is a pooling layer. It performs max pooling with pool size 2*2\n",
    "# Then we apply dropout with probability 0.2\n",
    "# Since the output after dropout is still a 2D image we flatten it for further processing.\n",
    "# This is followed by another layer having 128 units and activation function  = relu\n",
    "# Finally we have the output layer with softmax activation function\n",
    "\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(5,5),input_shape = (1,28,28),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    # Now we can compile the model by specifying loss, optimizer and metircs\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "187s - loss: 0.2453 - acc: 0.9303 - val_loss: 0.0754 - val_acc: 0.9783\n",
      "Epoch 2/10\n",
      "182s - loss: 0.0714 - acc: 0.9783 - val_loss: 0.0465 - val_acc: 0.9847\n",
      "Epoch 3/10\n",
      "183s - loss: 0.0488 - acc: 0.9858 - val_loss: 0.0433 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "182s - loss: 0.0392 - acc: 0.9882 - val_loss: 0.0379 - val_acc: 0.9876\n",
      "Epoch 5/10\n",
      "187s - loss: 0.0303 - acc: 0.9908 - val_loss: 0.0324 - val_acc: 0.9899\n",
      "Epoch 6/10\n",
      "181s - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0338 - val_acc: 0.9891\n",
      "Epoch 7/10\n",
      "184s - loss: 0.0226 - acc: 0.9925 - val_loss: 0.0361 - val_acc: 0.9872\n",
      "Epoch 8/10\n",
      "181s - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0344 - val_acc: 0.9886\n",
      "Epoch 9/10\n",
      "183s - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0360 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      "183s - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0314 - val_acc: 0.9897\n",
      "Model loss and accuracy is  : [0.031393288964495877, 0.98970000000000002]\n"
     ]
    }
   ],
   "source": [
    "# We will evaluate the model performance by first training the model.\n",
    "# verbose = 2 will print performance at each epoch while zero means silent\n",
    "model = base_model()\n",
    "model.fit(X_train,y_train,batch_size=200,epochs=10,verbose=2,validation_data=(X_test,y_test))\n",
    "\n",
    "# Now we evaluate the model \n",
    "base_model_score = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Model loss and accuracy is  : '+str(base_model_score))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
